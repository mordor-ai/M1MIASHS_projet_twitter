{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyMiG6yzu+t3G5ptp7GLwqnR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mordor-ai/M1MIASHS_projet_twitter/blob/master/analyse_100M_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPzsqLDKj41w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "71e00066-dd3c-4b80-9de8-846f19664bad"
      },
      "source": [
        "!apt-get install libcairo2-dev"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcairo-script-interpreter2 libpixman-1-dev libxcb-shm0-dev\n",
            "Suggested packages:\n",
            "  libcairo2-doc\n",
            "The following NEW packages will be installed:\n",
            "  libcairo-script-interpreter2 libcairo2-dev libpixman-1-dev libxcb-shm0-dev\n",
            "0 upgraded, 4 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 930 kB of archives.\n",
            "After this operation, 3,986 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Fetched 930 kB in 1s (949 kB/s)\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "(Reading database ... 144568 files and directories currently installed.)\n",
            "Preparing to unpack .../libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaupgPzyJMr2",
        "colab_type": "code",
        "outputId": "a976eb23-87e0-4bd0-9bab-ababd9db82c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install python-igraph\n",
        "!pip install pycairo"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-igraph in /usr/local/lib/python3.6/dist-packages (0.8.2)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.6/dist-packages (from python-igraph) (1.6.2)\n",
            "Collecting pycairo\n",
            "  Using cached https://files.pythonhosted.org/packages/e8/9d/c8be300fc6b1298559d37a071c3833b0b251e0fff334d2e4c408d5789162/pycairo-1.19.1.tar.gz\n",
            "Building wheels for collected packages: pycairo\n",
            "  Building wheel for pycairo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycairo: filename=pycairo-1.19.1-cp36-cp36m-linux_x86_64.whl size=241267 sha256=20320023c73c060600884ccb7da3ee8770efbb9026b43b834ca6a36caf429740\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/08/71/ef11d2526c2cb17a581088a89dfe1258f17c911e55ebde0550\n",
            "Successfully built pycairo\n",
            "Installing collected packages: pycairo\n",
            "Successfully installed pycairo-1.19.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOK_ICdMhS7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9ae87ca7-6f49-4ed1-8a2b-2e2527cb25d5"
      },
      "source": [
        "!git clone https://github.com/mordor-ai/M1MIASHS_projet_twitter.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'M1MIASHS_projet_twitter'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/60)\u001b[K\rremote: Counting objects:   3% (2/60)\u001b[K\rremote: Counting objects:   5% (3/60)\u001b[K\rremote: Counting objects:   6% (4/60)\u001b[K\rremote: Counting objects:   8% (5/60)\u001b[K\rremote: Counting objects:  10% (6/60)\u001b[K\rremote: Counting objects:  11% (7/60)\u001b[K\rremote: Counting objects:  13% (8/60)\u001b[K\rremote: Counting objects:  15% (9/60)\u001b[K\rremote: Counting objects:  16% (10/60)\u001b[K\rremote: Counting objects:  18% (11/60)\u001b[K\rremote: Counting objects:  20% (12/60)\u001b[K\rremote: Counting objects:  21% (13/60)\u001b[K\rremote: Counting objects:  23% (14/60)\u001b[K\rremote: Counting objects:  25% (15/60)\u001b[K\rremote: Counting objects:  26% (16/60)\u001b[K\rremote: Counting objects:  28% (17/60)\u001b[K\rremote: Counting objects:  30% (18/60)\u001b[K\rremote: Counting objects:  31% (19/60)\u001b[K\rremote: Counting objects:  33% (20/60)\u001b[K\rremote: Counting objects:  35% (21/60)\u001b[K\rremote: Counting objects:  36% (22/60)\u001b[K\rremote: Counting objects:  38% (23/60)\u001b[K\rremote: Counting objects:  40% (24/60)\u001b[K\rremote: Counting objects:  41% (25/60)\u001b[K\rremote: Counting objects:  43% (26/60)\u001b[K\rremote: Counting objects:  45% (27/60)\u001b[K\rremote: Counting objects:  46% (28/60)\u001b[K\rremote: Counting objects:  48% (29/60)\u001b[K\rremote: Counting objects:  50% (30/60)\u001b[K\rremote: Counting objects:  51% (31/60)\u001b[K\rremote: Counting objects:  53% (32/60)\u001b[K\rremote: Counting objects:  55% (33/60)\u001b[K\rremote: Counting objects:  56% (34/60)\u001b[K\rremote: Counting objects:  58% (35/60)\u001b[K\rremote: Counting objects:  60% (36/60)\u001b[K\rremote: Counting objects:  61% (37/60)\u001b[K\rremote: Counting objects:  63% (38/60)\u001b[K\rremote: Counting objects:  65% (39/60)\u001b[K\rremote: Counting objects:  66% (40/60)\u001b[K\rremote: Counting objects:  68% (41/60)\u001b[K\rremote: Counting objects:  70% (42/60)\u001b[K\rremote: Counting objects:  71% (43/60)\u001b[K\rremote: Counting objects:  73% (44/60)\u001b[K\rremote: Counting objects:  75% (45/60)\u001b[K\rremote: Counting objects:  76% (46/60)\u001b[K\rremote: Counting objects:  78% (47/60)\u001b[K\rremote: Counting objects:  80% (48/60)\u001b[K\rremote: Counting objects:  81% (49/60)\u001b[K\rremote: Counting objects:  83% (50/60)\u001b[K\rremote: Counting objects:  85% (51/60)\u001b[K\rremote: Counting objects:  86% (52/60)\u001b[K\rremote: Counting objects:  88% (53/60)\u001b[K\rremote: Counting objects:  90% (54/60)\u001b[K\rremote: Counting objects:  91% (55/60)\u001b[K\rremote: Counting objects:  93% (56/60)\u001b[K\rremote: Counting objects:  95% (57/60)\u001b[K\rremote: Counting objects:  96% (58/60)\u001b[K\rremote: Counting objects:  98% (59/60)\u001b[K\rremote: Counting objects: 100% (60/60)\u001b[K\rremote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/46)\u001b[K\rremote: Compressing objects:   4% (2/46)\u001b[K\rremote: Compressing objects:   6% (3/46)\u001b[K\rremote: Compressing objects:   8% (4/46)\u001b[K\rremote: Compressing objects:  10% (5/46)\u001b[K\rremote: Compressing objects:  13% (6/46)\u001b[K\rremote: Compressing objects:  15% (7/46)\u001b[K\rremote: Compressing objects:  17% (8/46)\u001b[K\rremote: Compressing objects:  19% (9/46)\u001b[K\rremote: Compressing objects:  21% (10/46)\u001b[K\rremote: Compressing objects:  23% (11/46)\u001b[K\rremote: Compressing objects:  26% (12/46)\u001b[K\rremote: Compressing objects:  28% (13/46)\u001b[K\rremote: Compressing objects:  30% (14/46)\u001b[K\rremote: Compressing objects:  32% (15/46)\u001b[K\rremote: Compressing objects:  34% (16/46)\u001b[K\rremote: Compressing objects:  36% (17/46)\u001b[K\rremote: Compressing objects:  39% (18/46)\u001b[K\rremote: Compressing objects:  41% (19/46)\u001b[K\rremote: Compressing objects:  43% (20/46)\u001b[K\rremote: Compressing objects:  45% (21/46)\u001b[K\rremote: Compressing objects:  47% (22/46)\u001b[K\rremote: Compressing objects:  50% (23/46)\u001b[K\rremote: Compressing objects:  52% (24/46)\u001b[K\rremote: Compressing objects:  54% (25/46)\u001b[K\rremote: Compressing objects:  56% (26/46)\u001b[K\rremote: Compressing objects:  58% (27/46)\u001b[K\rremote: Compressing objects:  60% (28/46)\u001b[K\rremote: Compressing objects:  63% (29/46)\u001b[K\rremote: Compressing objects:  65% (30/46)\u001b[K\rremote: Compressing objects:  67% (31/46)\u001b[K\rremote: Compressing objects:  69% (32/46)\u001b[K\rremote: Compressing objects:  71% (33/46)\u001b[K\rremote: Compressing objects:  73% (34/46)\u001b[K\rremote: Compressing objects:  76% (35/46)\u001b[K\rremote: Compressing objects:  78% (36/46)\u001b[K\rremote: Compressing objects:  80% (37/46)\u001b[K\rremote: Compressing objects:  82% (38/46)\u001b[K\rremote: Compressing objects:  84% (39/46)\u001b[K\rremote: Compressing objects:  86% (40/46)\u001b[K\rremote: Compressing objects:  89% (41/46)\u001b[K\rremote: Compressing objects:  91% (42/46)\u001b[K\rremote: Compressing objects:  93% (43/46)\u001b[K\rremote: Compressing objects:  95% (44/46)\u001b[K\rremote: Compressing objects:  97% (45/46)\u001b[K\rremote: Compressing objects: 100% (46/46)\u001b[K\rremote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "Unpacking objects:   1% (1/60)   \rUnpacking objects:   3% (2/60)   \rUnpacking objects:   5% (3/60)   \rUnpacking objects:   6% (4/60)   \rUnpacking objects:   8% (5/60)   \rUnpacking objects:  10% (6/60)   \rUnpacking objects:  11% (7/60)   \rUnpacking objects:  13% (8/60)   \rUnpacking objects:  15% (9/60)   \rUnpacking objects:  16% (10/60)   \rUnpacking objects:  18% (11/60)   \rUnpacking objects:  20% (12/60)   \rUnpacking objects:  21% (13/60)   \rUnpacking objects:  23% (14/60)   \rUnpacking objects:  25% (15/60)   \rUnpacking objects:  26% (16/60)   \rUnpacking objects:  28% (17/60)   \rUnpacking objects:  30% (18/60)   \rUnpacking objects:  31% (19/60)   \rUnpacking objects:  33% (20/60)   \rUnpacking objects:  35% (21/60)   \rUnpacking objects:  36% (22/60)   \rUnpacking objects:  38% (23/60)   \rUnpacking objects:  40% (24/60)   \rUnpacking objects:  41% (25/60)   \rUnpacking objects:  43% (26/60)   \rUnpacking objects:  45% (27/60)   \rUnpacking objects:  46% (28/60)   \rUnpacking objects:  48% (29/60)   \rremote: Total 60 (delta 22), reused 39 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects:  50% (30/60)   \rUnpacking objects:  51% (31/60)   \rUnpacking objects:  53% (32/60)   \rUnpacking objects:  55% (33/60)   \rUnpacking objects:  56% (34/60)   \rUnpacking objects:  58% (35/60)   \rUnpacking objects:  60% (36/60)   \rUnpacking objects:  61% (37/60)   \rUnpacking objects:  63% (38/60)   \rUnpacking objects:  65% (39/60)   \rUnpacking objects:  66% (40/60)   \rUnpacking objects:  68% (41/60)   \rUnpacking objects:  70% (42/60)   \rUnpacking objects:  71% (43/60)   \rUnpacking objects:  73% (44/60)   \rUnpacking objects:  75% (45/60)   \rUnpacking objects:  76% (46/60)   \rUnpacking objects:  78% (47/60)   \rUnpacking objects:  80% (48/60)   \rUnpacking objects:  81% (49/60)   \rUnpacking objects:  83% (50/60)   \rUnpacking objects:  85% (51/60)   \rUnpacking objects:  86% (52/60)   \rUnpacking objects:  88% (53/60)   \rUnpacking objects:  90% (54/60)   \rUnpacking objects:  91% (55/60)   \rUnpacking objects:  93% (56/60)   \rUnpacking objects:  95% (57/60)   \rUnpacking objects:  96% (58/60)   \rUnpacking objects:  98% (59/60)   \rUnpacking objects: 100% (60/60)   \rUnpacking objects: 100% (60/60), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8iePDrfhev7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0ebeb30-8ed6-4d10-c1b3-bbcc0e17d1f1"
      },
      "source": [
        "cd /content/M1MIASHS_projet_twitter"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/M1MIASHS_projet_twitter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHJXu6C3JI1i",
        "colab_type": "code",
        "outputId": "5795d307-1bc9-48fb-e5b3-17e8a5a8976e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import igraph\n",
        "import datetime\n",
        "\n",
        "\n",
        "\n",
        "def human_format(num):\n",
        "    magnitude = 0\n",
        "    while abs(num) >= 1000:\n",
        "        magnitude += 1\n",
        "        num /= 1000.0\n",
        "    # add more suffixes if you need them\n",
        "    return '%.0f%s' % (num, ['', 'K', 'M', 'G', 'T', 'P'][magnitude])\n",
        "\n",
        "\n",
        "n_rows = 10000000\n",
        "compressed = True\n",
        "tstart = None\n",
        "tend = None\n",
        "\n",
        "\n",
        "def start_time():\n",
        "    global tstart\n",
        "    tstart = datetime.datetime.now()\n",
        "\n",
        "\n",
        "def get_delta():\n",
        "    global tstart\n",
        "    tend = datetime.datetime.now()\n",
        "    return tend - tstart\n",
        "\n",
        "\n",
        "print('====== Profiling results =======')\n",
        "start_time()\n",
        "# load the original graph csv\n",
        "df_edges = pd.read_csv(\n",
        "    \"./files/twitter_100M.csv\",\n",
        "    header='infer',\n",
        "    sep=' ',\n",
        "    low_memory=False#,\n",
        "   # dtype={'source': np.int32, 'target': np.int32}\n",
        "     #,nrows=n_rows\n",
        ")\n",
        "# on renome les colonnes\n",
        "df_edges.columns = ['source', 'target']\n",
        "delta1 = get_delta()\n",
        "print('Time required to load edges: %(delta1)s' % locals())\n",
        "start_time()\n",
        "\n",
        "# on charge tout les noeuds\n",
        "df_nodes = pd.read_csv(\n",
        "    \"./files/twitter-2010-ids.csv\",\n",
        "    header='infer',\n",
        "    sep=',',\n",
        "    low_memory=False#,\n",
        "   # dtype={'node_id': np.int32, 'twitter_id': np.int32}\n",
        "    #, nrows = n_rows\n",
        "    #,index_col='node_id'\n",
        ")\n",
        "delta2 = get_delta()\n",
        "\n",
        "print(\"Dataframe loaded with \" + str(len(df_edges)) + \"rows.\")\n",
        "print('Time required to load nodes: %(delta2)s' % locals())\n",
        "print(df_edges.head())\n",
        "print(df_nodes.head())\n",
        "#print(df_nodes.to_dict('records'))\n",
        "#print(df_edges.to_dict('records'))\n",
        "print(\"Now loading graph\")\n",
        "start_time()\n",
        "# chargement du graphe\n",
        "g = igraph.Graph.DictList(df_nodes.to_dict('records')\n",
        "                          , df_edges.to_dict('records')\n",
        "                          , directed=True\n",
        "                          , vertex_name_attr='node_id'\n",
        "                          , edge_foreign_keys=('source', 'target')\n",
        "                          #, iterative=False\n",
        "                          )\n",
        "delta2 = get_delta()\n",
        "print(\"graph loaded\")\n",
        "print('Time required to load graph: %(delta2)s' % locals())\n",
        "print(\"loading graph summary\")\n",
        "\n",
        "start_time()\n",
        "igraph.summary(g)\n",
        "delta1 = get_delta()\n",
        "print('Time required to get summary graph: %(delta1)s' % locals())\n",
        "\n",
        "# start_time()\n",
        "# degrees_in = g.degree(mode=\"in\")\n",
        "# max_deg_in = max(degrees_in)\n",
        "# print(max_deg_in)\n",
        "# df_degree_in = [g.vs[idx].attributes() for idx, eb in enumerate(degrees_in) if eb == max_deg_in]\n",
        "# print(df_degree_in)\n",
        "# print(\" twitter id  having max degree IN: \", df_degree_in)\n",
        "# delta1 = get_delta()\n",
        "# print('Time required to get  graph degree in : %(delta1)s' % locals())\n",
        "#\n",
        "#\n",
        "# start_time()\n",
        "# degrees_out = g.degree(mode=\"out\")\n",
        "# max_deg_out = max(degrees_out)\n",
        "# print(max_deg_out)\n",
        "# df_degree_out = [g.vs[idx].attributes() for idx, eb in enumerate(degrees_out) if eb == max_deg_out]\n",
        "# print(df_degree_out)\n",
        "# print(\" twitter id  having max degree OUT: \", df_degree_out)\n",
        "# delta1 = get_delta()\n",
        "# print('Time required to get  graph degree out : %(delta1)s' % locals())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file_name: str = './files/twitter_' + human_format(n_rows) + '_pickle'+  ('z' if compressed else '')\n",
        "print(\"now saving graph to \", file_name)\n",
        "start_time()\n",
        "if compressed:\n",
        "    g.write_picklez(file_name)\n",
        "else:\n",
        "    g.write_pickle(file_name)\n",
        "print(\"graph saved\")\n",
        "delta4 = get_delta()\n",
        "print(\"Time required to save pickle file: %(delta4)s\" % locals())\n",
        "print(\"====== End of program =======\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== Profiling results =======\n",
            "Time required to load edges: 0:00:00.368997\n",
            "Dataframe loaded with 2086819rows.\n",
            "Time required to load nodes: 0:00:00.381494\n",
            "   source  target\n",
            "0       3     2.0\n",
            "1       2     3.0\n",
            "2       5     4.0\n",
            "3       4     5.0\n",
            "4       5     6.0\n",
            "   node_id  twitter_id\n",
            "0        0  56862681.0\n",
            "1        1  15767971.0\n",
            "2        2  22055653.0\n",
            "3        3  23219170.0\n",
            "4        4  24503384.0\n",
            "Now loading graph\n",
            "graph loaded\n",
            "Time required to load graph: 0:00:22.360405\n",
            "loading graph summary\n",
            "IGRAPH D--- 3149737 2086819 -- \n",
            "+ attr: node_id (v), twitter_id (v), source (e), target (e)\n",
            "Time required to get summary graph: 0:00:00.000178\n",
            "now saving graph to  ./files/twitter_10M_picklez\n",
            "graph saved\n",
            "Time required to save pickle file: 0:01:12.421214\n",
            "====== End of program =======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfLYoF4SJMUD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}